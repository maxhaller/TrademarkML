{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:28.596553Z",
     "end_time": "2023-11-05T08:44:28.606337Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "gt = pd.read_csv('../TMSIM-500/data.csv', sep=',', encoding='utf-8')\n",
    "X = pd.read_csv('../notebooks/word_mark_X.csv', sep=',', encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:28.729310Z",
     "end_time": "2023-11-05T08:44:28.893308Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "word_gt = gt.loc[gt['Type'] == 'word']\n",
    "y = word_gt[['Outcome']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:28.893308Z",
     "end_time": "2023-11-05T08:44:28.930352Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "      damerau  four_cosine  four_jaccard  four_n_gram  four_overlap  \\\n0         5.0          0.0           0.0     0.714286           0.0   \n1         5.0          0.0           0.0     0.714286           0.0   \n2         5.0          0.0           0.0     0.714286           0.0   \n3         5.0          0.0           0.0     0.714286           0.0   \n4         5.0          0.0           0.0     0.714286           0.0   \n...       ...          ...           ...          ...           ...   \n6510      5.0          0.0           0.0     0.625000           0.0   \n6511      5.0          0.0           0.0     0.625000           0.0   \n6512      5.0          0.0           0.0     0.625000           0.0   \n6513      5.0          0.0           0.0     0.625000           0.0   \n6514      5.0          0.0           0.0     0.625000           0.0   \n\n      four_q_gram        jw  lcs  lev  metric_lcs  ...  \\\n0             4.0  0.809524  5.0  5.0    0.714286  ...   \n1             4.0  0.809524  5.0  5.0    0.714286  ...   \n2             4.0  0.809524  5.0  5.0    0.714286  ...   \n3             4.0  0.809524  5.0  5.0    0.714286  ...   \n4             4.0  0.809524  5.0  5.0    0.714286  ...   \n...           ...       ...  ...  ...         ...  ...   \n6510          5.0  0.854167  5.0  5.0    0.625000  ...   \n6511          5.0  0.854167  5.0  5.0    0.625000  ...   \n6512          5.0  0.854167  5.0  5.0    0.625000  ...   \n6513          5.0  0.854167  5.0  5.0    0.625000  ...   \n6514          5.0  0.854167  5.0  5.0    0.625000  ...   \n\n      metaphone3_three_q_gram  metaphone3_two_cosine  metaphone3_two_jaccard  \\\n0                         1.0               0.707107                     0.5   \n1                         1.0               0.707107                     0.5   \n2                         1.0               0.707107                     0.5   \n3                         1.0               0.707107                     0.5   \n4                         1.0               0.707107                     0.5   \n...                       ...                    ...                     ...   \n6510                      0.0               0.000000                     0.0   \n6511                      0.0               0.000000                     0.0   \n6512                      0.0               0.000000                     0.0   \n6513                      0.0               0.000000                     0.0   \n6514                      0.0               0.000000                     0.0   \n\n      metaphone3_two_n_gram  metaphone3_two_overlap  metaphone3_two_q_gram  \\\n0                  0.333333                     1.0                    1.0   \n1                  0.333333                     1.0                    1.0   \n2                  0.333333                     1.0                    1.0   \n3                  0.333333                     1.0                    1.0   \n4                  0.333333                     1.0                    1.0   \n...                     ...                     ...                    ...   \n6510               1.000000                     0.0                    1.0   \n6511               1.000000                     0.0                    1.0   \n6512               1.000000                     0.0                    1.0   \n6513               1.000000                     0.0                    1.0   \n6514               1.000000                     0.0                    1.0   \n\n      conc_lev_wordnet  conc_cos_wordnet  conc_lcs_wordnet  \\\n0             0.166667          0.117647          0.117647   \n1             0.166667          0.117647          0.117647   \n2             0.166667          0.117647          0.117647   \n3             0.166667          0.117647          0.117647   \n4             0.166667          0.117647          0.117647   \n...                ...               ...               ...   \n6510          0.250000          1.000000          1.000000   \n6511          0.250000          1.000000          1.000000   \n6512          0.250000          1.000000          1.000000   \n6513          0.250000          1.000000          1.000000   \n6514          0.250000          1.000000          1.000000   \n\n      spacy_item_similarity  \n0                  0.219071  \n1                  0.201852  \n2                  0.273260  \n3                  0.147323  \n4                  0.385672  \n...                     ...  \n6510               0.491092  \n6511               0.734926  \n6512               0.376833  \n6513               0.580209  \n6514               0.292360  \n\n[6515 rows x 76 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>damerau</th>\n      <th>four_cosine</th>\n      <th>four_jaccard</th>\n      <th>four_n_gram</th>\n      <th>four_overlap</th>\n      <th>four_q_gram</th>\n      <th>jw</th>\n      <th>lcs</th>\n      <th>lev</th>\n      <th>metric_lcs</th>\n      <th>...</th>\n      <th>metaphone3_three_q_gram</th>\n      <th>metaphone3_two_cosine</th>\n      <th>metaphone3_two_jaccard</th>\n      <th>metaphone3_two_n_gram</th>\n      <th>metaphone3_two_overlap</th>\n      <th>metaphone3_two_q_gram</th>\n      <th>conc_lev_wordnet</th>\n      <th>conc_cos_wordnet</th>\n      <th>conc_lcs_wordnet</th>\n      <th>spacy_item_similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.714286</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.809524</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.707107</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.166667</td>\n      <td>0.117647</td>\n      <td>0.117647</td>\n      <td>0.219071</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.714286</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.809524</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.707107</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.166667</td>\n      <td>0.117647</td>\n      <td>0.117647</td>\n      <td>0.201852</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.714286</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.809524</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.707107</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.166667</td>\n      <td>0.117647</td>\n      <td>0.117647</td>\n      <td>0.273260</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.714286</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.809524</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.707107</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.166667</td>\n      <td>0.117647</td>\n      <td>0.117647</td>\n      <td>0.147323</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.714286</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.809524</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.707107</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.166667</td>\n      <td>0.117647</td>\n      <td>0.117647</td>\n      <td>0.385672</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6510</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.854167</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.625000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.491092</td>\n    </tr>\n    <tr>\n      <th>6511</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.854167</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.625000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.734926</td>\n    </tr>\n    <tr>\n      <th>6512</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.854167</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.625000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.376833</td>\n    </tr>\n    <tr>\n      <th>6513</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.854167</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.625000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.580209</td>\n    </tr>\n    <tr>\n      <th>6514</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.854167</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.625000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.292360</td>\n    </tr>\n  </tbody>\n</table>\n<p>6515 rows × 76 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:29.045228Z",
     "end_time": "2023-11-05T08:44:29.096171Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 1, ..., 0, 0, 0])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "y = binarizer.fit_transform(y).ravel()\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:29.180074Z",
     "end_time": "2023-11-05T08:44:29.219147Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "X['outcome'] = y\n",
    "X['ID'] = word_gt['Case ID']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:29.339042Z",
     "end_time": "2023-11-05T08:44:29.354579Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "      damerau  four_cosine  four_jaccard  four_n_gram  four_overlap  \\\n0         5.0          0.0           0.0     0.714286           0.0   \n1         5.0          0.0           0.0     0.714286           0.0   \n2         5.0          0.0           0.0     0.714286           0.0   \n3         5.0          0.0           0.0     0.714286           0.0   \n4         5.0          0.0           0.0     0.714286           0.0   \n...       ...          ...           ...          ...           ...   \n6510      5.0          0.0           0.0     0.625000           0.0   \n6511      5.0          0.0           0.0     0.625000           0.0   \n6512      5.0          0.0           0.0     0.625000           0.0   \n6513      5.0          0.0           0.0     0.625000           0.0   \n6514      5.0          0.0           0.0     0.625000           0.0   \n\n      four_q_gram        jw  lcs  lev  metric_lcs  ...  \\\n0             4.0  0.809524  5.0  5.0    0.714286  ...   \n1             4.0  0.809524  5.0  5.0    0.714286  ...   \n2             4.0  0.809524  5.0  5.0    0.714286  ...   \n3             4.0  0.809524  5.0  5.0    0.714286  ...   \n4             4.0  0.809524  5.0  5.0    0.714286  ...   \n...           ...       ...  ...  ...         ...  ...   \n6510          5.0  0.854167  5.0  5.0    0.625000  ...   \n6511          5.0  0.854167  5.0  5.0    0.625000  ...   \n6512          5.0  0.854167  5.0  5.0    0.625000  ...   \n6513          5.0  0.854167  5.0  5.0    0.625000  ...   \n6514          5.0  0.854167  5.0  5.0    0.625000  ...   \n\n      metaphone3_two_jaccard  metaphone3_two_n_gram  metaphone3_two_overlap  \\\n0                        0.5               0.333333                     1.0   \n1                        0.5               0.333333                     1.0   \n2                        0.5               0.333333                     1.0   \n3                        0.5               0.333333                     1.0   \n4                        0.5               0.333333                     1.0   \n...                      ...                    ...                     ...   \n6510                     0.0               1.000000                     0.0   \n6511                     0.0               1.000000                     0.0   \n6512                     0.0               1.000000                     0.0   \n6513                     0.0               1.000000                     0.0   \n6514                     0.0               1.000000                     0.0   \n\n      metaphone3_two_q_gram  conc_lev_wordnet  conc_cos_wordnet  \\\n0                       1.0          0.166667          0.117647   \n1                       1.0          0.166667          0.117647   \n2                       1.0          0.166667          0.117647   \n3                       1.0          0.166667          0.117647   \n4                       1.0          0.166667          0.117647   \n...                     ...               ...               ...   \n6510                    1.0          0.250000          1.000000   \n6511                    1.0          0.250000          1.000000   \n6512                    1.0          0.250000          1.000000   \n6513                    1.0          0.250000          1.000000   \n6514                    1.0          0.250000          1.000000   \n\n      conc_lcs_wordnet  spacy_item_similarity  outcome         ID  \n0             0.117647               0.219071        1  003178074  \n1             0.117647               0.201852        1  003178074  \n2             0.117647               0.273260        1  003178074  \n3             0.117647               0.147323        1  003178074  \n4             0.117647               0.385672        1  003178074  \n...                ...                    ...      ...        ...  \n6510          1.000000               0.491092        0  003168317  \n6511          1.000000               0.734926        0  003168317  \n6512          1.000000               0.376833        0  003168317  \n6513          1.000000               0.580209        0  003168317  \n6514          1.000000               0.292360        0  003168317  \n\n[6515 rows x 78 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>damerau</th>\n      <th>four_cosine</th>\n      <th>four_jaccard</th>\n      <th>four_n_gram</th>\n      <th>four_overlap</th>\n      <th>four_q_gram</th>\n      <th>jw</th>\n      <th>lcs</th>\n      <th>lev</th>\n      <th>metric_lcs</th>\n      <th>...</th>\n      <th>metaphone3_two_jaccard</th>\n      <th>metaphone3_two_n_gram</th>\n      <th>metaphone3_two_overlap</th>\n      <th>metaphone3_two_q_gram</th>\n      <th>conc_lev_wordnet</th>\n      <th>conc_cos_wordnet</th>\n      <th>conc_lcs_wordnet</th>\n      <th>spacy_item_similarity</th>\n      <th>outcome</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.714286</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.809524</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.166667</td>\n      <td>0.117647</td>\n      <td>0.117647</td>\n      <td>0.219071</td>\n      <td>1</td>\n      <td>003178074</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.714286</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.809524</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.166667</td>\n      <td>0.117647</td>\n      <td>0.117647</td>\n      <td>0.201852</td>\n      <td>1</td>\n      <td>003178074</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.714286</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.809524</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.166667</td>\n      <td>0.117647</td>\n      <td>0.117647</td>\n      <td>0.273260</td>\n      <td>1</td>\n      <td>003178074</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.714286</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.809524</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.166667</td>\n      <td>0.117647</td>\n      <td>0.117647</td>\n      <td>0.147323</td>\n      <td>1</td>\n      <td>003178074</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.714286</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.809524</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.166667</td>\n      <td>0.117647</td>\n      <td>0.117647</td>\n      <td>0.385672</td>\n      <td>1</td>\n      <td>003178074</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6510</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.854167</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.625000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.491092</td>\n      <td>0</td>\n      <td>003168317</td>\n    </tr>\n    <tr>\n      <th>6511</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.854167</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.625000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.734926</td>\n      <td>0</td>\n      <td>003168317</td>\n    </tr>\n    <tr>\n      <th>6512</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.854167</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.625000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.376833</td>\n      <td>0</td>\n      <td>003168317</td>\n    </tr>\n    <tr>\n      <th>6513</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.854167</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.625000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.580209</td>\n      <td>0</td>\n      <td>003168317</td>\n    </tr>\n    <tr>\n      <th>6514</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.854167</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.625000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.292360</td>\n      <td>0</td>\n      <td>003168317</td>\n    </tr>\n  </tbody>\n</table>\n<p>6515 rows × 78 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:29.821245Z",
     "end_time": "2023-11-05T08:44:29.864723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=.20, n_splits=1, random_state = 42)\n",
    "split = splitter.split(X, groups=X['ID'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train = X.iloc[train_inds]\n",
    "test = X.iloc[test_inds]\n",
    "#gss = GroupShuffleSplit(n_splits=2, train_size=.7, random_state=42).split(X, y, gt['Case ID'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:30.035387Z",
     "end_time": "2023-11-05T08:44:30.058474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "feature_cols = [c for c in X.columns if c not in ['outcome', 'ID']]\n",
    "y_train = train['outcome']\n",
    "x_train = train[feature_cols]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:31.163755Z",
     "end_time": "2023-11-05T08:44:31.187831Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "y_test = test['outcome']\n",
    "x_test = test[feature_cols]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:31.288365Z",
     "end_time": "2023-11-05T08:44:31.331433Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#split = GroupShuffleSplit(n_splits=10, train_size=.8, random_state=42).split(X=x_train, y=y_train, groups=word_gt['Case ID'])\n",
    "#gridsearch = GridSearchCV(SVC(), cv=split, param_grid={'kernel':('linear', 'rbf'), 'C': [0.1, 1, 10],                      'gamma': [1, 0.1]})\n",
    "#gridsearch.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:31.469217Z",
     "end_time": "2023-11-05T08:44:31.491659Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#svm = SVC(kernel='linear', C=1, gamma=0.1)\n",
    "#svm.fit(x_train, y_train)\n",
    "\n",
    "#sfs_forward = SequentialFeatureSelector(\n",
    "#    svm, n_features_to_select=5, direction=\"forward\"\n",
    "#).fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:32.032952Z",
     "end_time": "2023-11-05T08:44:32.078024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "cols = X.columns\n",
    "vis_features = [c for c in cols if not c.startswith('metaphone') and not c.startswith('conc_') and not c.startswith('spacy') and not c in ['outcome', 'ID']]\n",
    "aur_features = [c for c in cols if c.startswith('metaphone')]\n",
    "con_features = [c for c in cols if c.startswith('conc_')]\n",
    "it_features = [c for c in cols if c.endswith('item_similarity')]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:44:32.353043Z",
     "end_time": "2023-11-05T08:44:32.371553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['damerau',\n 'four_cosine',\n 'four_jaccard',\n 'four_n_gram',\n 'four_overlap',\n 'four_q_gram',\n 'jw',\n 'lcs',\n 'lev',\n 'metric_lcs',\n 'normalized_lev',\n 'osa',\n 'sift',\n 'sorensen',\n 'three_cosine',\n 'three_jaccard',\n 'three_n_gram',\n 'three_overlap',\n 'three_q_gram',\n 'two_cosine',\n 'two_jaccard',\n 'two_n_gram',\n 'two_overlap',\n 'two_q_gram']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-04T18:16:53.693932Z",
     "end_time": "2023-11-04T18:16:53.711079Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: damerau, metaphone2_damerau, conc_lev_wordnet, spacy_item_similarity\n",
      "1: 0.7918834547346514\n",
      "2: damerau, metaphone2_damerau, conc_cos_wordnet, spacy_item_similarity\n",
      "2: 0.7923287671232878\n",
      "3: damerau, metaphone2_damerau, conc_lcs_wordnet, spacy_item_similarity\n",
      "3: 0.6995932597327135\n",
      "4: damerau, metaphone2_four_cosine, conc_lev_wordnet, spacy_item_similarity\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 20\u001B[0m\n\u001B[0;32m     16\u001B[0m split \u001B[38;5;241m=\u001B[39m GroupShuffleSplit(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, train_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m.8\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\u001B[38;5;241m.\u001B[39msplit(X\u001B[38;5;241m=\u001B[39mx_train, y\u001B[38;5;241m=\u001B[39my_train, groups\u001B[38;5;241m=\u001B[39mword_gt\u001B[38;5;241m.\u001B[39mloc[train_inds, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCase ID\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     17\u001B[0m gridsearch \u001B[38;5;241m=\u001B[39m GridSearchCV(rf, cv\u001B[38;5;241m=\u001B[39msplit, param_grid\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m75\u001B[39m],\n\u001B[0;32m     18\u001B[0m                                                     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_features\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlog2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msqrt\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     19\u001B[0m                                                     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m50\u001B[39m]}, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 20\u001B[0m \u001B[43mgridsearch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m gridsearch\u001B[38;5;241m.\u001B[39mpredict(x_test[[v, a, c, i]])\n\u001B[0;32m     22\u001B[0m acc \u001B[38;5;241m=\u001B[39m accuracy_score(y_pred\u001B[38;5;241m=\u001B[39my_pred, y_true\u001B[38;5;241m=\u001B[39my_test)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    892\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    893\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    894\u001B[0m     )\n\u001B[0;32m    896\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 898\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    901\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    902\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1421\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1422\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    837\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    838\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    839\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    841\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    842\u001B[0m         )\n\u001B[0;32m    843\u001B[0m     )\n\u001B[1;32m--> 845\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    849\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    854\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    865\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    866\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    867\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     64\u001B[0m )\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1088\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1088\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1089\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1092\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[0;32m   1094\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    727\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    728\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 729\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    732\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[0;32m    733\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    445\u001B[0m trees \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    446\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_estimator(append\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39mrandom_state)\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_more_estimators)\n\u001B[0;32m    448\u001B[0m ]\n\u001B[0;32m    450\u001B[0m \u001B[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001B[39;00m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001B[39;00m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;66;03m# making threading more efficient than multiprocessing in\u001B[39;00m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001B[39;00m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;66;03m# parallel_backend contexts set at a higher level,\u001B[39;00m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;66;03m# since correctness does not rely on using threads.\u001B[39;00m\n\u001B[1;32m--> 456\u001B[0m trees \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mthreads\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_build_trees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    462\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    463\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    464\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    465\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    466\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[43m        \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    468\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    469\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    470\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    471\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    472\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    473\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    474\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[38;5;66;03m# Collect newly grown trees\u001B[39;00m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mextend(trees)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     64\u001B[0m )\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1088\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1088\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1089\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1092\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[0;32m   1094\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:175\u001B[0m, in \u001B[0;36m_parallel_build_trees\u001B[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    173\u001B[0m     curr_sample_weight \u001B[38;5;241m=\u001B[39m sample_weight\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m--> 175\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[43m_generate_sample_indices\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    178\u001B[0m sample_counts \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mbincount(indices, minlength\u001B[38;5;241m=\u001B[39mn_samples)\n\u001B[0;32m    179\u001B[0m curr_sample_weight \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m sample_counts\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:132\u001B[0m, in \u001B[0;36m_generate_sample_indices\u001B[1;34m(random_state, n_samples, n_samples_bootstrap)\u001B[0m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;124;03mPrivate function used to _parallel_build_trees function.\"\"\"\u001B[39;00m\n\u001B[0;32m    131\u001B[0m random_instance \u001B[38;5;241m=\u001B[39m check_random_state(random_state)\n\u001B[1;32m--> 132\u001B[0m sample_indices \u001B[38;5;241m=\u001B[39m \u001B[43mrandom_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sample_indices\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "counter = 1\n",
    "result = ''\n",
    "best_f1 = 0\n",
    "best_iteration = 0\n",
    "best_gridsearch = None\n",
    "for v in vis_features:\n",
    "    for a in aur_features:\n",
    "        for c in con_features:\n",
    "            for i in it_features:\n",
    "                print(f'{counter}: {v}, {a}, {c}, {i}')\n",
    "                split = GroupShuffleSplit(n_splits=4, train_size=.8, random_state=42).split(X=x_train, y=y_train, groups=word_gt.loc[train_inds, 'Case ID'])\n",
    "                gridsearch = GridSearchCV(rf, cv=split, param_grid={'max_depth': [25, 50, 75],\n",
    "                                                                    'max_features': ['log2', 'sqrt'],\n",
    "                                                                    'n_estimators': [15, 20, 50]}, scoring='f1')\n",
    "                gridsearch.fit(x_train[[v, a, c, i]], y_train)\n",
    "                y_pred = gridsearch.predict(x_test[[v, a, c, i]])\n",
    "                acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "                precision = precision_score(y_pred=y_pred, y_true=y_test)\n",
    "                recall = recall_score(y_pred=y_pred, y_true=y_test)\n",
    "                auc = roc_auc_score(y_score=y_pred, y_true=y_test)\n",
    "                f1 = f1_score(y_pred=y_pred, y_true=y_test)\n",
    "                result += f'\\n{counter}: {v}, {a}, {c}, {i}\\n\\naccuracy: {acc}\\nprecision: {precision}\\nrecall: {recall}\\nroc: {auc}\\nf1: {f1}\\n\\nbest params: {gridsearch.best_params_}\\nbest scoring: {gridsearch.best_score_}\\ncv-results: {gridsearch.cv_results_}'\n",
    "                if best_f1 < f1:\n",
    "                    best_f1 = f1\n",
    "                    best_iteration = counter\n",
    "                    best_gridsearch = gridsearch\n",
    "                print(f'{counter}: {f1}')\n",
    "                counter += 1\n",
    "\n",
    "\n",
    "with open('results_rf_new.txt', 'w') as file:\n",
    "    file.write(f'best iteration: {best_iteration}\\n\\n\\n' + result)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('best_rf.pickle', 'wb') as pickle_file:\n",
    "    pickle_file.write(best_gridsearch.best_estimator_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-04T01:01:10.367240Z",
     "end_time": "2023-11-04T06:15:31.938723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "with open('test_model.pickle', 'wb') as pickle_file:\n",
    "    pickle.dump(best_gridsearch.best_estimator_, pickle_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:13:37.683322Z",
     "end_time": "2023-11-05T08:13:37.700636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "rrf = gridsearch.best_estimator_\n",
    "\n",
    "rrf.feature_importances_\n",
    "import pickle\n",
    "with open('test_model.pickle', 'wb') as pickle_file:\n",
    "    pickle.dump(gridsearch.best_estimator_, pickle_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-04T17:46:57.357317Z",
     "end_time": "2023-11-04T17:46:57.372182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.23663095, 0.13089771, 0.25993377, 0.37253757])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "with open('test_model.pickle', 'rb') as o:\n",
    "    rrf = pickle.load(o)\n",
    "rrf.feature_importances_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:27:21.805691Z",
     "end_time": "2023-11-05T08:27:22.314025Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: damerau, metaphone2_damerau, conc_lev_wordnet, spacy_item_similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.81069743051914\n",
      "2: damerau, metaphone2_damerau, conc_cos_wordnet, spacy_item_similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 0.8312932410856839\n",
      "3: damerau, metaphone2_damerau, conc_lcs_wordnet, spacy_item_similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\maxha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mpl = MLPClassifier(random_state = 42)\n",
    "counter = 1\n",
    "result = ''\n",
    "best_f1 = 0\n",
    "best_iteration = 0\n",
    "best_gridsearch = None\n",
    "for v in vis_features:\n",
    "    for a in aur_features:\n",
    "        for c in con_features:\n",
    "            for i in it_features:\n",
    "                print(f'{counter}: {v}, {a}, {c}, {i}')\n",
    "                split = GroupShuffleSplit(n_splits=4, train_size=.8, random_state=42).split(X=x_train, y=y_train, groups=word_gt.loc[train_inds, 'Case ID'])\n",
    "                gridsearch = GridSearchCV(mpl, cv=split, param_grid={\n",
    "                    'hidden_layer_sizes': [(45,2,11,), (3,)],\n",
    "                    'max_iter': [150],\n",
    "                    'activation': ['relu'],\n",
    "                    'solver': ['adam'],\n",
    "                    'alpha': [0.0001, 0.05],\n",
    "                    'learning_rate': ['constant','adaptive'],\n",
    "                })\n",
    "                gridsearch.fit(x_train[[v, a, c, i]], y_train)\n",
    "                y_pred = gridsearch.predict(x_test[[v, a, c, i]])\n",
    "                acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "                precision = precision_score(y_pred=y_pred, y_true=y_test)\n",
    "                recall = recall_score(y_pred=y_pred, y_true=y_test)\n",
    "                auc = roc_auc_score(y_score=y_pred, y_true=y_test)\n",
    "                f1 = f1_score(y_pred=y_pred, y_true=y_test)\n",
    "                result += f'\\n{counter}: {v}, {a}, {c}, {i}\\n\\naccuracy: {acc}\\nprecision: {precision}\\nrecall: {recall}\\nroc: {auc}\\nf1: {f1}\\n\\nbest params: {gridsearch.best_params_}\\nbest scoring: {gridsearch.best_score_}\\ncv-results: {gridsearch.cv_results_}'\n",
    "                if best_f1 < f1:\n",
    "                    best_f1 = f1\n",
    "                    best_iteration = counter\n",
    "                    best_gridsearch = gridsearch\n",
    "                print(f'{counter}: {f1}')\n",
    "                counter += 1\n",
    "\n",
    "\n",
    "with open('results_mlp_new.txt', 'w') as file:\n",
    "    file.write(f'best iteration: {best_iteration}\\n\\n\\n' + result)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('best_mlp.pickle', 'wb') as pickle_file:\n",
    "    pickle_file.write(best_gridsearch.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23663095 0.13089771 0.25993377 0.37253757]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(rrf.feature_importances_)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feat_importances = pd.Series(rrf.feature_importances_, index=['lcs', 'metaphone3_two_cosine', 'conc', 'spacy_item_similarity'])\n",
    "feat_importances.nlargest(4).plot(kind='barh')\n",
    "plt.title(\"Top 15 important features\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:28:42.778401Z",
     "end_time": "2023-11-05T08:28:43.151640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8020190689848571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, RobustScaler\n",
    "\n",
    "ssc = MinMaxScaler()\n",
    "x_train_scaled = ssc.fit_transform(x_train[['lcs', 'metaphone3_two_cosine', 'spacy_item_similarity']])\n",
    "x_test_scaled = ssc.transform(x_test[['lcs', 'metaphone3_two_cosine', 'spacy_item_similarity']])\n",
    "\n",
    "opt_rf = RandomForestClassifier(max_depth=100, max_features='sqrt', n_estimators=70, random_state=42)\n",
    "opt_rf.fit(x_train[['lcs', 'metaphone3_two_cosine', 'spacy_item_similarity']], y_train)\n",
    "y_pred = opt_rf.predict(x_test[['lcs', 'metaphone3_two_cosine', 'spacy_item_similarity']])\n",
    "print(f1_score(y_pred=y_pred, y_true=y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-04T17:39:52.534533Z",
     "end_time": "2023-11-04T17:39:53.271661Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
